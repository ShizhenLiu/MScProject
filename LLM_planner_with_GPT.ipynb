{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LcsM5zuMvEo"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "openai.api_key = input()\n",
        "\n",
        "test = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": \"Hello ChatGPT, does this work?\"}\n",
        "  ]\n",
        "  )"
      ],
      "metadata": {
        "id": "-t8M4L1KIBod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.choices[0].message.role"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "017fXE_HZ7WB",
        "outputId": "67312d0a-cf8c-49a9-fd17-f48f255cb371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'assistant'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_prompt = \"\"\"\n",
        "You are an assistant for the game Minecraft.\n",
        "I will give you some target object and some knowledge related to the object. Please write the\n",
        "obtaining of the object as a goal in the standard form.\n",
        "The standard form of the task is as follows:\n",
        "{\n",
        "Task\n",
        "“description”: specific description of the task\n",
        "}\n",
        "\n",
        "To complete the task, you need to play the role of a scheduler, scheduling individual agents to complete the task at different stages of the task.\n",
        "\n",
        "The following agents are now available for various tasks, each specialising in a different skill:\n",
        "Tree Chopping Agent: This agent completes the subtask of collecting logs, you can specify the number of logs. Below is an example of scheduling instruction to a Tree Chopper agent, when the agent collects 8 logs the agent will stop working and report on the status of the item bar:\n",
        "{\n",
        "“agent_name”: chopping_tree_agent,\n",
        "“count”: 8\n",
        "}\n",
        "\n",
        "Crafting Agent: This agent can do the subtask of crafting items and you can specify the object and number of object to be crafted. Below is an example of s scheduling instruction to a s crafting agent, when the agent has crafted 64 wooden planks the agent will stop working and report on the item bar status:\n",
        "{\n",
        "“agent_name”: carfting_agent,\n",
        "“object”: wooden_planks\n",
        "“count”: 64\n",
        "}\n",
        "\n",
        "Navigation Agent: This agent can move in four directions, south, east, north, and west, and the distance travelled is calculated in chunks (Area of size 16 x 16). The following is an example of scheduling instruction to a navigation agent：\n",
        "{\n",
        "“agent_name”: navigation_agent,\n",
        "“direction”: north,\n",
        "“distance”: 3\n",
        "}\n",
        "\n",
        "You can only schedule one agent at a time. And you can only reschedule or schedule the next agent after an agent completes or fails a subtask. After I answer \"Current subtask complete\", you answer the next scheduling instruction.\n",
        "Your scheduling instructions must conform to the format in the example above and be included in the first sentence of the answer.\n",
        "If you have completed understanding the above, please answer \"Yes\". I will then enter the task.\n",
        "\"\"\"\n",
        "\n",
        "task_prompt= \"\"\"\n",
        "{\n",
        "Task\n",
        "“description”: You need to first collect 8 logs. Then you need to create 32 planks and wooden pickaxe, and in the process you need to create workbenches and sticks. Finally, you need to carry these to 3 blocks away in the north.\n",
        "}\n",
        "\n",
        "Only one scheduling instruction can be included in an answer!\n",
        "You don't need to answer the reason you chose the scheduling instruction, just answer the scheduling instruction.\n",
        "Your answer must be in strict compliance with the format of the scheduling instructions\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "yS0PKzF5Nwes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "class LLM_planner:\n",
        "    def __init__(self, key='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') -> None:\n",
        "        self.key = key\n",
        "        openai.api_key = self.key\n",
        "        self.full_text = []\n",
        "        # self.chatWithGPT(role='system', prompt=context_prompt)\n",
        "\n",
        "    def reset(self):\n",
        "        self.full_text.clear()\n",
        "        self.chatWithGPT(role='system', prompt=context_prompt)\n",
        "\n",
        "    def chatWithGPT(self, role='user', prompt=''):\n",
        "        self.full_text.append(\n",
        "        {\"role\": role, \"content\": prompt}\n",
        "        )\n",
        "\n",
        "        completion = openai.ChatCompletion.create(\n",
        "        model = \"gpt-3.5-turbo\",\n",
        "        messages = self.full_text\n",
        "        )\n",
        "\n",
        "        self.full_text.append(\n",
        "        {\"role\": completion.choices[0].message.role, \"content\": completion.choices[0].message.content}\n",
        "        )\n",
        "\n",
        "        return completion.choices[0].message.content\n",
        "\n",
        "    def call_chopping_tree_agent(count=0):\n",
        "        pass\n",
        "\n",
        "    def call_carfting_agent(object='', count=0):\n",
        "        pass\n",
        "\n",
        "    def call_navigation_agent(direction='north', distance=0):\n",
        "        pass\n",
        "\n",
        "    def agent_scheduler(self, response):\n",
        "        response = ast.literal_eval(response)\n",
        "\n",
        "        if response['agent_name'] == 'chopping_tree_agent':\n",
        "            status = self.call_chopping_tree_agent(count=response['count'])\n",
        "        elif response['agent_name'] == 'carfting_agent':\n",
        "            status = self.call_carfting_agent(object=response['object'], count=response['count'])\n",
        "        elif response['agent_name'] == 'navigation_agent':\n",
        "            status = self.call_navigation_agent(direction=response['direction'], distance=response['distance'])\n",
        "        else:\n",
        "            raise Exception(\"No such agent\")\n",
        "\n",
        "        return status"
      ],
      "metadata": {
        "id": "Kj1Nj1enJy0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#key = input()\n",
        "test1 = LLM_planner()"
      ],
      "metadata": {
        "id": "h2Bzv54oayj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test1.chatWithGPT(role='system', prompt=context_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0lSQr1z0b8kJ",
        "outputId": "7aeeb393-d15b-45e7-8c33-1bf8eac49bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aaa = test1.chatWithGPT(role='user', prompt=task_prompt)\n",
        "print(aaa)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3eAnDGtcYIz",
        "outputId": "7acb4c7c-75ba-4026-8642-28433282769a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "\"agent_name\": \"chopping_tree_agent\",\n",
            "\"count\": 8\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aaa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZqgLhcHLdW4t",
        "outputId": "a22b60bd-d0ee-4755-887e-ec90731f4129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\\n\"agent_name\": \"chopping_tree_agent\",\\n\"count\": 8\\n}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "dict2 = ast.literal_eval(aaa)\n",
        "dict2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWVaEfg3dIqm",
        "outputId": "ff692ff2-a5ec-426d-e345-993ac0829af6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'agent_name': 'chopping_tree_agent', 'count': 8}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict2['count'] == 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx4pGc69dppg",
        "outputId": "cb253e65-d4d0-46f0-c629-4b1f7d1771b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatWithGPT(context_prompt + task_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e08fJkI9J6Aa",
        "outputId": "11b3cc5c-be5c-4fba-ea05-8f196efa0f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "Task\n",
            "\"description\": \"Collect 8 logs.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatWithGPT(\"Current subtask complete\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9yExov-OKHi",
        "outputId": "daa2449c-ab2f-48c4-d666-c686a8f09b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Great job! What is the next subtask that needs to be completed?\n"
          ]
        }
      ]
    }
  ]
}